{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.datasets import mnist\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def input_data():\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n\n\n    return X_test, y_test, X_train, y_train\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(X_train, y_train, n_folds=5):\n    accuracy = []\n    data = []\n\n    kfold = KFold(n_folds, shuffle=True, random_state=1)\n\n    for train_ix, test_ix in kfold.split(X_train):\n        model = create_model()\n\n        train_X, train_y, test_X, test_y = X_train[train_ix], y_train[train_ix], X_train[test_ix], y_train[test_ix]\n\n        data_fit = model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=10, batch_size=32, verbose=0)\n        \n        _, acc = model.evaluate(test_X, test_y, verbose=0)\n        \n        accuracy.append(acc)\n        data.append(data_fit)\n    \n    return accuracy, data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_diagnostics(data):\n    for i in range(len(data)):\n        plt.subplot(2, 1, 1)\n        plt.title('Cross Entropy Loss')\n        plt.plot(data[i].history['loss'], color='red', label='train')\n        plt.plot(data[i].history['val_loss'], color='orange', label='test')\n        \n        plt.subplot(2, 1, 2)\n        plt.title('Classification Accuracy')\n        plt.plot(data[i].history['accuracy'], color='blue', label='train')\n        plt.plot(data[i].history['val_accuracy'], color='orange', label='test')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_performance(acc):\n    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (np.mean(acc) * 100, np.std(acc) * 100, len(acc)))\n    plt.boxplot(acc)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(X_train, model):\n    test_images = X_train[1:5]\n    test_images = test_images.reshape(test_images.shape[0], 28, 28)\n\n    for i, test_image in enumerate(test_images, start=1):\n        org_image = test_image\n        test_image = test_image.reshape(1, 28, 28, 1)\n        prediction = model.predict_classes(test_image, verbose=0)\n\n        print(\"Predicted digit: {}\".format(prediction[0]))\n        plt.subplot(220 + i)\n        plt.axis('off')\n        plt.title(\"Predicted digit: {}\".format(prediction[0]))\n        plt.imshow(org_image, cmap=plt.get_cmap('gray'))\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    X_test, y_test, X_train, y_train = input_data()\n    accuracy, data = evaluate_model(X_train, y_train)\n    summarize_diagnostics(data)\n    summarize_performance(accuracy)\n\n    model = create_model()\n    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n    test(X_train, model)\n\n    model_json = model.to_json()\n    with open(\"model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(\"model.h5\")\n    print(\"Saved model to disk\")\n\n    img = cv2.imread('TestNumber.png')\n    prediction = predict(img)\n    print(\"Predicted Number:\", prediction)\n\nrun()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}